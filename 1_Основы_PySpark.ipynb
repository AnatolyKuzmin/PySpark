{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f144fb57-b165-4b55-b118-91fbf186dbca",
   "metadata": {},
   "source": [
    "# 1. Основы PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd723522-9d3e-4f8e-b099-5656a15b755a",
   "metadata": {},
   "source": [
    "Установите Java (обязательно!). Скачайте Amazon Corretto 11 (или OpenJDK 11).  \n",
    "```\n",
    "# Проверка (в PowerShell):\n",
    "java -version\n",
    "```\n",
    "Установите Python 3.11. Скачайте с официального сайта. При установке отметьте \"Add Python to PATH\".  \n",
    "```\n",
    "python --version\n",
    "pip --version\n",
    "```\n",
    "Установите Hadoop и Spark. Скачайте Spark 3.5.x (предпочтительно) и Hadoop 3.3. Распакуйте архив в C:\\spark (или другой путь без пробелов). Скачайте winutils.exe для Hadoop в папку C:\\hadoop\\bin. Добавьте переменные среды:\n",
    "```\n",
    "[System.Environment]::SetEnvironmentVariable(\"HADOOP_HOME\", \"C:\\hadoop\", \"Machine\")\n",
    "[System.Environment]::SetEnvironmentVariable(\"SPARK_HOME\", \"C:\\spark\", \"Machine\")\n",
    "[System.Environment]::SetEnvironmentVariable(\"PATH\", \"$env:PATH;C:\\spark\\bin;C:\\hadoop\\bin\", \"Machine\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61767cb0-7665-4058-8690-950b29c46303",
   "metadata": {},
   "source": [
    "Установите PySpark и зависимости\n",
    "```\n",
    "pip install pyspark pandas jupyter pyarrow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61879ce-7486-4c23-9077-1981728a1780",
   "metadata": {},
   "source": [
    "Проверка установки. Тест PySpark в Jupyter\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "В ноутбуке выполните\n",
    "```\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Test\") \\\n",
    "    .getOrCreate()\n",
    "df = spark.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], [\"id\", \"name\"])\n",
    "df.show()\n",
    "```\n",
    "Вывод\n",
    "\n",
    "| id| name|\n",
    "| -- | -- |\n",
    "|  1|Alice|\n",
    "|  2|  Bob|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d4d85-606d-4747-8eb4-b0c3357cdd7d",
   "metadata": {},
   "source": [
    "## 1.1. Введение в Spark и RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66d445-4c6d-46b6-89c4-38e8e4f16c4c",
   "metadata": {},
   "source": [
    "PySpark — это Python API для Apache Spark — высокопроизводительной распределённой платформы для обработки больших данных. Позволяет писать параллельные программы, которые работают на кластерах, но при этом использовать знакомый Python. Spark работает с большими объёмами данных, поддерживает SQL, машинное обучение, потоковую обработку. Jupyter Notebook — удобный инструмент для интерактивного написания и запуска кода, идеально подходит для обучения и прототипирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6135ff-0229-4983-93d4-6b38fd44c3a8",
   "metadata": {},
   "source": [
    "## 1.2. DataFrames (основы)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df15083e-e2d9-4afc-844c-23229d66cfe1",
   "metadata": {},
   "source": [
    "## 1.3. Базовые операции с DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89093b6a-0637-445b-9453-84d918a3e00c",
   "metadata": {},
   "source": [
    "## 1.4. Работа с дубликатами и пропусками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ca272-bb80-4848-a66a-2adf0eb822fb",
   "metadata": {},
   "source": [
    "## 1.5. SQL-синтаксис в PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c63abf-de87-41ba-9b7f-60a3a66f604c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
