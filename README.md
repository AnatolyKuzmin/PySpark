# PySpark

Стартовые требования:
- Python (ООП, pandas, numpy)
- Базовый SQL
- Установленные: Java 8/11, PySpark 3.3+, Jupyter Lab

## Основы PySpark

### Введение и установка

- Что такое PySpark и зачем он нужен
- Архитектура Spark: драйвер, воркеры, executor, cluster manager
- Установка Spark и настройка окружения в Jupyter Notebook (через findspark)
- Проверка работы: создание SparkSession

### RDD и DataFrame — базовые структуры

### Основные трансформации и действия

### Работа с DataFrame

### Итог недели и мини-проект

## Работа с данными и SQL

### Чтение и запись данных

### Работа с пропущенными значениями и типами

### Работа с датами и строками

### Введение в Spark SQL

### Джоины и объединения

## Оптимизация и расширенные возможности

### Оптимизация кода и партиционирование

### UDF (User Defined Functions)

### Работа с большими файлами

### Использование оконных функций

### Работа с вложенными структурами

### Мини-проект

##  Экспертный уровень и интеграция

### Производительность и отладка

### Интеграция с другими инструментами

### Машинное обучение в PySpark (MLlib)

### Потоковая обработка (Structured Streaming)

### Лучшие практики и паттерны

## Проект
