{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cc9b16-83bc-49be-a7d5-5f6d6cb635a1",
   "metadata": {},
   "source": [
    "# 2. Продвинутые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8e4d63-7a2d-4b2b-b6b0-a96039bdb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['HADOOP_USER_NAME'] = 'root'  # Обход проверки пользователя\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Test\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9ef16-8985-4bb8-945c-aa836c7fe09f",
   "metadata": {},
   "source": [
    "## 2.1 Оконные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e67184-586f-410b-87b3-e5e89fb3ff7c",
   "metadata": {},
   "source": [
    "Оконные функции (Window Functions) в PySpark позволяют выполнять вычисления над группами строк, сохраняя при этом индивидуальность каждой строки.\n",
    "\n",
    "Основные компоненты оконных функций:\n",
    "1. Оконная спецификация (WindowSpec) - определяет, какие строки будут включены в рамки окна для каждой строки\n",
    "2. Оконная функция - функция, которая применяется к данным в рамках окна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14de29-a4b1-40a3-b0fa-82f93f1782e0",
   "metadata": {},
   "source": [
    "**Ранжирование** (rank(), dense_rank(), row_number(), percent_rank())  \n",
    "**Агрегатные функции** (sum(), avg(), max(), min())  \n",
    "**Смещение** (lag(), lead())  \n",
    "**Аналитические функции** (first(), last(), cume_dist(), ntile())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e9389a-467a-4123-b971-fdeabfe507ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----------+----+\n",
      "|user_id|      date|amount|prev_amount|diff|\n",
      "+-------+----------+------+-----------+----+\n",
      "|      1|2023-01-10|   100|       NULL|NULL|\n",
      "|      1|2023-01-15|   200|        100| 100|\n",
      "|      1|2023-01-20|   300|        200| 100|\n",
      "|      2|2023-01-12|    50|       NULL|NULL|\n",
      "+-------+----------+------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Задача: Найти разницу между текущей и предыдущей покупкой для каждого пользователя.\n",
    "\n",
    "# Создаём DataFrame с покупками\n",
    "sales = spark.createDataFrame([\n",
    "    (1, \"2023-01-10\", 100),\n",
    "    (1, \"2023-01-15\", 200),\n",
    "    (2, \"2023-01-12\", 50),\n",
    "    (1, \"2023-01-20\", 300)\n",
    "], [\"user_id\", \"date\", \"amount\"])\n",
    "\n",
    "# Определяем окно\n",
    "from pyspark.sql.window import Window\n",
    "window = Window.partitionBy(\"user_id\").orderBy(\"date\")\n",
    "\n",
    "# Добавляем разницу с предыдущей покупкой\n",
    "from pyspark.sql.functions import lag, col\n",
    "sales_with_diff = sales.withColumn(\"prev_amount\", lag(\"amount\").over(window)).withColumn(\"diff\", col(\"amount\") - col(\"prev_amount\"))\n",
    "sales_with_diff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2c3323-79b2-4711-8ffc-d8ca0229d893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-----------+-----+----+\n",
      "|product_id|  name|   category|price|rank|\n",
      "+----------+------+-----------+-----+----+\n",
      "|         1|Laptop|Electronics|  999|   1|\n",
      "|         2| Phone|Electronics|  699|   2|\n",
      "|         3|  Desk|  Furniture|  200|   1|\n",
      "|         4| Chair|  Furniture|  150|   2|\n",
      "+----------+------+-----------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Топ-3 товара по категориям\n",
    "\n",
    "# Данные о товарах\n",
    "products = spark.createDataFrame([\n",
    "    (1, \"Laptop\", \"Electronics\", 999),\n",
    "    (2, \"Phone\", \"Electronics\", 699),\n",
    "    (3, \"Desk\", \"Furniture\", 200),\n",
    "    (4, \"Chair\", \"Furniture\", 150)\n",
    "], [\"product_id\", \"name\", \"category\", \"price\"])\n",
    "\n",
    "# Окно для ранжирования\n",
    "window = Window.partitionBy(\"category\").orderBy(col(\"price\").desc())\n",
    "\n",
    "# Топ-3 в каждой категории\n",
    "from pyspark.sql.functions import dense_rank\n",
    "top_products = products.withColumn(\"rank\", dense_rank().over(window)).filter(col(\"rank\") <= 3)\n",
    "top_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ca967-07c1-4419-922b-a48575154614",
   "metadata": {},
   "source": [
    "## 2.2 Работа с датами и строками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e6b26-7e20-4291-99d3-d47783340d75",
   "metadata": {},
   "source": [
    "## 2.3 Оптимизация (партиционирование, кэширование)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f5688-a85f-4043-aaee-be5bfadf960f",
   "metadata": {},
   "source": [
    "## 2.4 UDF (пользовательские функции)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e21f63-5441-4d7e-a652-70789cc9aab0",
   "metadata": {},
   "source": [
    "## 2.5 Чтение/запись в разных форматах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ea360-3271-4591-b0b6-6e51aead9d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
