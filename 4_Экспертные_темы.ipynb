{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c894e5",
   "metadata": {},
   "source": [
    "# 4. Экспертные темы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a9f2f",
   "metadata": {},
   "source": [
    "## 4.1. Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406dd4e4-59c1-4108-9c96-e8a4c210f8db",
   "metadata": {},
   "source": [
    "Delta Lake — это открытый формат хранения данных, который добавляет ACID-транзакции, управление метаданными и другие enterprise-функции к вашим данным в Data Lakes.\n",
    "\n",
    "| Функции | Преимущество |\n",
    "| - | - |\n",
    "| ACID-транзакции | Гарантированная целостность данных при параллельныхзапросах |\n",
    "| Time Travel | Доступ к историческим данным |\n",
    "| Schema Enforcement | Контроль схема при записи |\n",
    "| Upsert/Delete | Поддержка операций MERGE, UPDATE, DELETE |\n",
    "| Оптимизация файлов | Автоматическая компактификация маленьких файлов |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d0910-f282-4d62-adc9-2cdcbd0df4da",
   "metadata": {},
   "source": [
    "Установка `pip install delta-spark`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8c4c5-c3b5-4f20-aba0-741ac741abd1",
   "metadata": {},
   "source": [
    "Инициализация Spark с Delta\n",
    "```\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLake\") \\\n",
    "    .config(\"spark.jars\", \"/path/to/delta-core_2.12.jar\") \\\n",
    "    .getOrCreate()\n",
    "```\n",
    "\n",
    "Создание Delta-таблицы\n",
    "```\n",
    "df.write.format(\"delta\").save(\"/data/delta/events\")\n",
    "\n",
    "# С явным указанием схемы\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE events (\n",
    "    id LONG,\n",
    "    date STRING,\n",
    "    event_type STRING\n",
    "  ) USING DELTA\n",
    "  LOCATION '/data/delta/events'\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "Чтение данных\n",
    "```\n",
    "delta_df = spark.read.format(\"delta\").load(\"/data/delta/events\")\n",
    "\n",
    "# Чтение конкретной версии\n",
    "spark.read.format(\"delta\") \\\n",
    "  .option(\"versionAsOf\", 5) \\\n",
    "  .load(\"/data/delta/events\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4beb47a-c5ca-4f87-befa-6e491cd184e4",
   "metadata": {},
   "source": [
    "#### Time Travel — доступ к истории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a8cd2-7e63-4870-a7e7-d525dae06752",
   "metadata": {},
   "source": [
    "Просмотр истории изменений\n",
    "```\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, \"/data/delta/events\")\n",
    "history = delta_table.history()\n",
    "history.show()\n",
    "```\n",
    "\n",
    "Восстановление данных\n",
    "```\n",
    "# Восстановление до версии 2\n",
    "delta_table.restoreToVersion(2)\n",
    "\n",
    "# Восстановление до timestamp\n",
    "delta_table.restoreToTimestamp(\"2023-01-01 00:00:00\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9dc074-b15d-46fe-89b7-e5d877a80e14",
   "metadata": {},
   "source": [
    "#### Операции Upsert и Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41a86b-fba2-49ac-af1c-9f7b80681fa5",
   "metadata": {},
   "source": [
    "MERGE (Upsert)\n",
    "```\n",
    "updates_df = spark.createDataFrame([(1, \"new_data\")], [\"id\", \"data\"])\n",
    "\n",
    "delta_table.alias(\"target\").merge(\n",
    "    updates_df.alias(\"updates\"),\n",
    "    \"target.id = updates.id\"\n",
    ").whenMatchedUpdate(set={\"data\": \"updates.data\"}) \\\n",
    " .whenNotMatchedInsert(values={\n",
    "    \"id\": \"updates.id\",\n",
    "    \"data\": \"updates.data\"\n",
    "}).execute()\n",
    "```\n",
    "\n",
    "Удаление данных\n",
    "```\n",
    "delta_table.delete(\"date < '2023-01-01'\")  # Удалить старые записи\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dae66a-ed46-4bcc-8996-fdc63ff1719f",
   "metadata": {},
   "source": [
    "#### Оптимизация Delta-таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27835c9-af05-447a-9128-e4eca966be21",
   "metadata": {},
   "source": [
    "Компактификация файлов\n",
    "```\n",
    "delta_table.optimize().executeCompaction()\n",
    "```\n",
    "\n",
    "Z-Ordering (кластеризация)\n",
    "```\n",
    "delta_table.optimize().executeZOrderBy(\"event_type\")\n",
    "```\n",
    "\n",
    "Вакуумирование (удаление старых версий)\n",
    "```\n",
    "delta_table.vacuum()                  # Удалить версии старше 7 дней\n",
    "delta_table.vacuum(48)                # Удалить версии старше 48 часов\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c4604-70ba-437e-bbb7-78774443f83d",
   "metadata": {},
   "source": [
    "#### Практический кейс: CDC (Change Data Capture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b2d34-6790-4234-a4ad-d658696825c9",
   "metadata": {},
   "source": [
    "Задача: Реализовать обработку изменений из источника в Delta Lake.\n",
    "```\n",
    "# 1. Создаём стриминг из Kafka\n",
    "changes = spark.readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"subscribe\", \"updates\") \\\n",
    "  .load()\n",
    "\n",
    "# 2. Парсим JSON-сообщения\n",
    "parsed = changes.select(\n",
    "  from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
    ").select(\"data.*\")\n",
    "\n",
    "# 3. Записываем изменения в Delta с MERGE\n",
    "def upsert_to_delta(microBatchDF, batchId):\n",
    "    delta_table = DeltaTable.forPath(spark, \"/data/delta/target\")\n",
    "    delta_table.alias(\"t\").merge(\n",
    "        microBatchDF.alias(\"s\"),\n",
    "        \"t.id = s.id\"\n",
    "    ).whenMatchedUpdateAll() \\\n",
    "     .whenNotMatchedInsertAll() \\\n",
    "     .execute()\n",
    "\n",
    "parsed.writeStream \\\n",
    "  .foreachBatch(upsert_to_delta) \\\n",
    "  .option(\"checkpointLocation\", \"/checkpoints/delta_cdc\") \\\n",
    "  .start()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1fa64e-b29a-49ee-876e-0af2770e56bd",
   "metadata": {},
   "source": [
    "#### Мониторинг и обслуживание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a9c3d-4ee8-4030-a5ea-4f48b54cd9ee",
   "metadata": {},
   "source": [
    "Анализ метаданных\n",
    "```\n",
    "spark.sql(\"ANALYZE TABLE events COMPUTE STATISTICS\")\n",
    "spark.sql(\"DESCRIBE DETAIL events\").show()\n",
    "```\n",
    "\n",
    "Размеры файлов\n",
    "```\n",
    "spark.sql(\"\"\"\n",
    "  SELECT file_size, num_records \n",
    "  FROM delta.`/data/delta/events`.files\n",
    "\"\"\").show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90baba3",
   "metadata": {},
   "source": [
    "## 4.2. MLlib (машинное обучение)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19516a91",
   "metadata": {},
   "source": [
    "## 4.3. Распределенная обработка (Glue, EMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb31e6d",
   "metadata": {},
   "source": [
    "## 4.4. Отладка и логирование  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
